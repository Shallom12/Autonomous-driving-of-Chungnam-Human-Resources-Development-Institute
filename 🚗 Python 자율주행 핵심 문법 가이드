ììœ¨ì£¼í–‰ ê°œë°œì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” Python í•µì‹¬ ë¬¸ë²•ë“¤ì„ ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œì™€ í•¨ê»˜ ì •ë¦¬í•œ ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨
- [ë°˜ë³µë¬¸ (while, for)](#ë°˜ë³µë¬¸-while-for)
- [ë°°ì—´ ì²˜ë¦¬](#ë°°ì—´-ì²˜ë¦¬)
- [í•¨ìˆ˜ ì •ì˜ (def)](#í•¨ìˆ˜-ì •ì˜-def)
- [í´ë˜ìŠ¤ ì •ì˜ (class)](#í´ë˜ìŠ¤-ì •ì˜-class)
- [ì¡°ê±´ë¬¸ í™œìš©](#ì¡°ê±´ë¬¸-í™œìš©)
- [ì˜ˆì™¸ ì²˜ë¦¬](#ì˜ˆì™¸-ì²˜ë¦¬)
- [ì œì–´ë¬¸ (continue, pass)](#ì œì–´ë¬¸-continue-pass)

---

## ğŸ”„ ë°˜ë³µë¬¸ (while, for)

### ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ì²˜ë¦¬ while ë£¨í”„

```python
import cv2

# ë¹„ë””ì˜¤ ìº¡ì²˜ ê°ì²´ ìƒì„±
cap = cv2.VideoCapture(0)  # ì›¹ìº  ì‚¬ìš©

# ê¸°ë³¸ ë¹„ë””ì˜¤ ì²˜ë¦¬ ë£¨í”„
while True:
    ret, frame = cap.read()  # í”„ë ˆì„ ì½ê¸°
    if not ret:              # í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨ì‹œ
        break                # ë£¨í”„ ì¢…ë£Œ
    
    # AI ëª¨ë¸ë¡œ ê°ì²´ íƒì§€
    results = model(frame)
    
    # í™”ë©´ì— í”„ë ˆì„ í‘œì‹œ
    cv2.imshow('frame', frame)
    
    # 'q' í‚¤ ì…ë ¥ì‹œ ì¢…ë£Œ
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# ìì› í•´ì œ
cap.release()
cv2.destroyAllWindows()
```

**ì‹¤í–‰ ê²°ê³¼:**
- ì›¹ìº ì´ ì¼œì§€ê³  ì‹¤ì‹œê°„ìœ¼ë¡œ ì˜ìƒì´ í™”ë©´ì— í‘œì‹œë©ë‹ˆë‹¤
- 'q' í‚¤ë¥¼ ëˆ„ë¥´ë©´ í”„ë¡œê·¸ë¨ì´ ì¢…ë£Œë©ë‹ˆë‹¤

### íƒì§€ ê²°ê³¼ ì²˜ë¦¬ for ë£¨í”„

```python
# ê° íƒì§€ ê²°ê³¼ ìˆœíšŒ
for result in results:
    boxes = result.boxes  # íƒì§€ëœ ê°ì²´ë“¤ì˜ ë°”ìš´ë”© ë°•ìŠ¤
    
    # ë°©ë²• 1: enumerateë¡œ ì¸ë±ìŠ¤ì™€ í•¨ê»˜ ìˆœíšŒ
    for i, box in enumerate(boxes):
        x1, y1, x2, y2 = box.xyxy[0]  # ì¢Œí‘œ ì¶”ì¶œ
        conf = box.conf[0]             # ì‹ ë¢°ë„
        cls = box.cls[0]               # í´ë˜ìŠ¤ ID
        
        print(f"ê°ì²´ {i}: ì¢Œí‘œ({x1}, {y1}, {x2}, {y2}), ì‹ ë¢°ë„: {conf:.2f}")

    # ë°©ë²• 2: ì¢Œí‘œ ë°°ì—´ ì§ì ‘ ìˆœíšŒ
    for i, (x1, y1, x2, y2) in enumerate(boxes):
        # ì‚¬ê°í˜• ê·¸ë¦¬ê¸° (ë…¹ìƒ‰, ë‘ê»˜ 2)
        cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)

    # ë°©ë²• 3: rangeë¡œ ì¸ë±ìŠ¤ ì ‘ê·¼
    for i in range(len(boxes)):
        if conf[i] > 0.5:  # ì‹ ë¢°ë„ 50% ì´ìƒë§Œ ì²˜ë¦¬
            # ê³ ì‹ ë¢°ë„ ê°ì²´ ì²˜ë¦¬ ë¡œì§
            pass
```

**ì‹¤í–‰ ê²°ê³¼:**
```
ê°ì²´ 0: ì¢Œí‘œ(150, 200, 350, 450), ì‹ ë¢°ë„: 0.85
ê°ì²´ 1: ì¢Œí‘œ(400, 100, 600, 300), ì‹ ë¢°ë„: 0.92
```

---

## ğŸ“Š ë°°ì—´ ì²˜ë¦¬

### ê¸°ë³¸ ë°°ì—´ ì¡°ì‘

```python
# ë¹ˆ ë¦¬ìŠ¤íŠ¸ ìƒì„±
detections = []      # íƒì§€ ê²°ê³¼ ì €ì¥ìš©
track_history = []   # ì¶”ì  íˆìŠ¤í† ë¦¬ ì €ì¥ìš©

# ë°°ì—´ì— ë°ì´í„° ì¶”ê°€
def add_detection(x1, y1, x2, y2, conf, cls):
    # íƒì§€ ì •ë³´ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥
    detections.append([x1, y1, x2, y2, conf, cls])
    
    # ì¤‘ì‹¬ì  ê³„ì‚° í›„ ì¶”ì  íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    cx = (x1 + x2) / 2
    cy = (y1 + y2) / 2
    track_history.append((cx, cy))
    
    print(f"íƒì§€ ì¶”ê°€: ì¤‘ì‹¬ì ({cx}, {cy})")

# ë°°ì—´ ê¸¸ì´ ì œí•œ (ìµœê·¼ Nê°œë§Œ ìœ ì§€)
def maintain_history_limit():
    if len(track_history) > 30:  # ìµœëŒ€ 30ê°œê¹Œì§€ë§Œ ìœ ì§€
        track_history.pop(0)     # ê°€ì¥ ì˜¤ë˜ëœ ê²ƒ ì œê±°
        print("ì˜¤ë˜ëœ ì¶”ì  ê¸°ë¡ ì œê±°")

# ë°°ì—´ ìŠ¬ë¼ì´ì‹±
recent_points = track_history[-10:]  # ìµœê·¼ 10ê°œ
print(f"ìµœê·¼ 10ê°œ í¬ì¸íŠ¸: {recent_points}")
```

**ì‹¤í–‰ ê²°ê³¼:**
```
íƒì§€ ì¶”ê°€: ì¤‘ì‹¬ì (250.0, 325.0)
íƒì§€ ì¶”ê°€: ì¤‘ì‹¬ì (500.0, 200.0)
ì˜¤ë˜ëœ ì¶”ì  ê¸°ë¡ ì œê±°
ìµœê·¼ 10ê°œ í¬ì¸íŠ¸: [(250.0, 325.0), (500.0, 200.0), ...]
```

---

## ğŸ”§ í•¨ìˆ˜ ì •ì˜ (def)

### ì°¨ì„  ê²€ì¶œ í•¨ìˆ˜

```python
def detect_lane_lines(img, roi_vertices, canny_low, canny_high, hough_threshold):
    """
    ì°¨ì„  ê²€ì¶œ í•¨ìˆ˜
    
    Args:
        img: ì…ë ¥ ì´ë¯¸ì§€ (numpy array)
        roi_vertices: ê´€ì‹¬ ì˜ì—­ ì¢Œí‘œ [(x1,y1), (x2,y2), ...]
        canny_low: Canny ì—£ì§€ ê²€ì¶œ í•˜ìœ„ ì„ê³„ê°’ (int)
        canny_high: Canny ì—£ì§€ ê²€ì¶œ ìƒìœ„ ì„ê³„ê°’ (int)
        hough_threshold: Hough ë³€í™˜ ì„ê³„ê°’ (int)
    
    Returns:
        lanes: ê²€ì¶œëœ ì°¨ì„  ë¦¬ìŠ¤íŠ¸
    """
    # 1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # 2. ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì ìš©
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    
    # 3. Canny ì—£ì§€ ê²€ì¶œ
    edges = cv2.Canny(blur, canny_low, canny_high)
    
    # 4. ê´€ì‹¬ ì˜ì—­ ë§ˆìŠ¤í‚¹
    mask = create_roi_mask(edges, roi_vertices)
    masked_edges = cv2.bitwise_and(edges, mask)
    
    # 5. Hough ë³€í™˜ìœ¼ë¡œ ì§ì„  ê²€ì¶œ
    lines = cv2.HoughLinesP(masked_edges, 1, np.pi/180, hough_threshold)
    
    return lines

# ì‚¬ìš© ì˜ˆì œ
roi_points = [(100, 400), (500, 400), (300, 250)]
lanes = detect_lane_lines(image, roi_points, 50, 150, 100)
print(f"ê²€ì¶œëœ ì°¨ì„  ìˆ˜: {len(lanes) if lanes is not None else 0}")
```

### ê°ì²´ í•„í„°ë§ í•¨ìˆ˜

```python
def filter_by_class(boxes, conf, cls, target_classes):
    """
    íŠ¹ì • í´ë˜ìŠ¤ì˜ ê°ì²´ë§Œ ê³¨ë¼ë‚´ëŠ” í•„í„° í•¨ìˆ˜
    
    Args:
        boxes: ê° ë¬¼ì²´ì˜ ìœ„ì¹˜ ì •ë³´ (ì‚¬ê°í˜• ì¢Œí‘œë“¤)
        conf: ê° ë¬¼ì²´ì˜ ì‹ ë¢°ë„ (0~1 ì ìˆ˜)
        cls: ê° ë¬¼ì²´ì˜ ì¢…ë¥˜ (ì˜ˆ: 'car', 'person', 'dog')
        target_classes: ìš°ë¦¬ê°€ ì°¾ê³  ì‹¶ì€ ë¬¼ì²´ ì¢…ë¥˜ë“¤
    
    Returns:
        filtered_boxes: í•„í„°ë§ëœ ë°•ìŠ¤ ë¦¬ìŠ¤íŠ¸
        filtered_conf: í•„í„°ë§ëœ ì‹ ë¢°ë„ ë¦¬ìŠ¤íŠ¸
    """
    # 1ë‹¨ê³„: ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì¤€ë¹„
    filtered_boxes = []  # ì„ íƒëœ ë¬¼ì²´ë“¤ì˜ ìœ„ì¹˜ë¥¼ ì €ì¥í•  ë¹ˆ í†µ
    filtered_conf = []   # ì„ íƒëœ ë¬¼ì²´ë“¤ì˜ ì‹ ë¢°ë„ë¥¼ ì €ì¥í•  ë¹ˆ í†µ
    
    # 2ë‹¨ê³„: ê° ë¬¼ì²´ë¥¼ í•˜ë‚˜ì”© ê²€ì‚¬
    for i, c in enumerate(cls):
        if c in target_classes:  # ì›í•˜ëŠ” í´ë˜ìŠ¤ì¸ê°€?
            filtered_boxes.append(boxes[i])
            filtered_conf.append(conf[i])
            print(f"í´ë˜ìŠ¤ {c} ê°ì²´ ì„ íƒë¨ (ì‹ ë¢°ë„: {conf[i]:.2f})")
    
    return filtered_boxes, filtered_conf

# ì‚¬ìš© ì˜ˆì œ
target = [0, 2, 3]  # person, car, motorcycleë§Œ ì„ íƒ
vehicles, vehicle_conf = filter_by_class(all_boxes, all_conf, all_cls, target)
print(f"í•„í„°ë§ ê²°ê³¼: {len(vehicles)}ê°œ ì°¨ëŸ‰ ê²€ì¶œ")
```

### ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤

```python
def calculate_center(x1, y1, x2, y2):
    """ë°”ìš´ë”© ë°•ìŠ¤ì˜ ì¤‘ì‹¬ì  ê³„ì‚°"""
    center_x = int((x1 + x2) / 2)
    center_y = int((y1 + y2) / 2)
    return center_x, center_y

def is_in_danger_zone(cx, cy, img_width, img_height):
    """ìœ„í—˜ êµ¬ì—­ì— ìˆëŠ”ì§€ í™•ì¸"""
    # í™”ë©´ í•˜ë‹¨ 70% ì´í•˜, ì¤‘ì•™ 40% ì˜ì—­
    bottom_threshold = img_height * 0.7
    left_threshold = img_width * 0.3
    right_threshold = img_width * 0.7
    
    return (cy > bottom_threshold and 
            cx > left_threshold and 
            cx < right_threshold)

# ì‚¬ìš© ì˜ˆì œ
cx, cy = calculate_center(100, 200, 300, 400)
if is_in_danger_zone(cx, cy, 800, 600):
    print("âš ï¸ ìœ„í—˜! ì°¨ëŸ‰ì´ ìœ„í—˜ êµ¬ì—­ì— ìˆìŠµë‹ˆë‹¤!")
else:
    print("âœ… ì•ˆì „ êµ¬ì—­ì…ë‹ˆë‹¤.")
```

**ì‹¤í–‰ ê²°ê³¼:**
```
í´ë˜ìŠ¤ 0 ê°ì²´ ì„ íƒë¨ (ì‹ ë¢°ë„: 0.85)
í´ë˜ìŠ¤ 2 ê°ì²´ ì„ íƒë¨ (ì‹ ë¢°ë„: 0.92)
í•„í„°ë§ ê²°ê³¼: 2ê°œ ì°¨ëŸ‰ ê²€ì¶œ
âš ï¸ ìœ„í—˜! ì°¨ëŸ‰ì´ ìœ„í—˜ êµ¬ì—­ì— ìˆìŠµë‹ˆë‹¤!
```

---

## ğŸ—ï¸ í´ë˜ìŠ¤ ì •ì˜ (class)

### ì°¨ëŸ‰ ì¶”ì  í´ë˜ìŠ¤

```python
class VehicleTracker:
    """ì°¨ëŸ‰ ì¶”ì ì„ ìœ„í•œ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ì´ˆê¸°í™” ë©”ì„œë“œ"""
        self.tracks = {}           # ì¶”ì  ì¤‘ì¸ ì°¨ëŸ‰ë“¤ {id: info}
        self.next_id = 0          # ë‹¤ìŒì— í• ë‹¹í•  ID
        self.max_disappeared = 10  # ìµœëŒ€ ì‹¤ì¢… í”„ë ˆì„ ìˆ˜
        print("ğŸš— ì°¨ëŸ‰ ì¶”ì ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def update_tracks(self, detections):
        """ì¶”ì  ì •ë³´ ì—…ë°ì´íŠ¸"""
        print(f"ğŸ“Š {len(detections)}ê°œ ì°¨ëŸ‰ íƒì§€ë¨")
        
        for detection in detections:
            # ê¸°ì¡´ ì¶”ì ê³¼ ë§¤ì¹­ ì‹œë„
            track_id = self.find_closest_track(detection)
            
            if track_id is None:
                # ìƒˆë¡œìš´ ì°¨ëŸ‰ ì¶”ì  ì‹œì‘
                self.create_new_track(detection)
            else:
                # ê¸°ì¡´ ì¶”ì  ì—…ë°ì´íŠ¸
                self.update_existing_track(track_id, detection)
    
    def create_new_track(self, detection):
        """ìƒˆë¡œìš´ ì¶”ì  ìƒì„±"""
        self.tracks[self.next_id] = {
            'position': detection,
            'disappeared': 0,
            'history': []
        }
        print(f"ğŸ†• ìƒˆ ì°¨ëŸ‰ ì¶”ì  ì‹œì‘: ID {self.next_id}")
        self.next_id += 1
    
    def find_closest_track(self, detection):
        """ê°€ì¥ ê°€ê¹Œìš´ ê¸°ì¡´ ì¶”ì  ì°¾ê¸°"""
        # ê°„ë‹¨í•œ ê±°ë¦¬ ê¸°ë°˜ ë§¤ì¹­
        min_distance = float('inf')
        closest_id = None
        
        for track_id, track_info in self.tracks.items():
            distance = self.calculate_distance(detection, track_info['position'])
            if distance < min_distance and distance < 50:  # ì„ê³„ê°’
                min_distance = distance
                closest_id = track_id
        
        return closest_id
    
    def calculate_distance(self, det1, det2):
        """ë‘ íƒì§€ ê²°ê³¼ ê°„ì˜ ê±°ë¦¬ ê³„ì‚°"""
        cx1, cy1 = calculate_center(*det1[:4])
        cx2, cy2 = calculate_center(*det2[:4])
        return ((cx1 - cx2) ** 2 + (cy1 - cy2) ** 2) ** 0.5

# ì‚¬ìš© ì˜ˆì œ
tracker = VehicleTracker()
detections = [[100, 200, 300, 400, 0.9, 2], [500, 150, 700, 350, 0.8, 2]]
tracker.update_tracks(detections)
```

### ììœ¨ì£¼í–‰ ë©”ì¸ í´ë˜ìŠ¤

```python
class AutonomousDriving:
    """ììœ¨ì£¼í–‰ ë©”ì¸ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.tracker = VehicleTracker()
        self.model = None  # AI ëª¨ë¸ (YOLO ë“±)
        self.current_speed = 0
        self.target_speed = 50
        print("ğŸ¤– ììœ¨ì£¼í–‰ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
    
    def process_frame(self, frame):
        """í”„ë ˆì„ ì²˜ë¦¬ ë° ì£¼í–‰ ê²°ì •"""
        # 1. ê°ì²´ íƒì§€
        detections = self.detect_objects(frame)
        
        # 2. ì°¨ëŸ‰ ì¶”ì  ì—…ë°ì´íŠ¸
        self.tracker.update_tracks(detections)
        
        # 3. ì£¼í–‰ ê²°ì •
        decision = self.make_driving_decision(detections)
        
        return decision
    
    def detect_objects(self, frame):
        """ê°ì²´ íƒì§€ (YOLO ëª¨ë¸ ì‚¬ìš©)"""
        if self.model is None:
            return []
        
        results = self.model(frame)
        detections = []
        
        for result in results:
            if result.boxes is not None:
                for box in result.boxes:
                    x1, y1, x2, y2 = box.xyxy[0]
                    conf = box.conf[0]
                    cls = box.cls[0]
                    detections.append([x1, y1, x2, y2, conf, cls])
        
        return detections
    
    def make_driving_decision(self, detections):
        """ì£¼í–‰ ê²°ì • ë¡œì§"""
        # ì „ë°© ì¥ì• ë¬¼ í™•ì¸
        if self.obstacle_ahead(detections):
            print("ğŸ›‘ ì „ë°© ì¥ì• ë¬¼ ê°ì§€ - ì œë™")
            return "brake"
        
        # ì°¨ì„  ë³€ê²½ í•„ìš”ì„± í™•ì¸
        elif self.lane_change_needed(detections):
            print("â†”ï¸ ì°¨ì„  ë³€ê²½ í•„ìš”")
            return "change_lane"
        
        else:
            print("âœ… ì§ì§„ ìœ ì§€")
            return "continue"
    
    def obstacle_ahead(self, detections):
        """ì „ë°© ì¥ì• ë¬¼ í™•ì¸"""
        for detection in detections:
            x1, y1, x2, y2, conf, cls = detection
            cx, cy = calculate_center(x1, y1, x2, y2)
            
            # ì „ë°© ì¤‘ì•™ êµ¬ì—­ì— ê³ ì‹ ë¢°ë„ ê°ì²´ê°€ ìˆëŠ”ê°€?
            if (conf > 0.7 and 
                cx > 300 and cx < 500 and  # ì¤‘ì•™ êµ¬ì—­
                cy > 400):                   # ê°€ê¹Œìš´ ê±°ë¦¬
                return True
        return False
    
    def lane_change_needed(self, detections):
        """ì°¨ì„  ë³€ê²½ í•„ìš”ì„± íŒë‹¨"""
        # ë‹¨ìˆœ ì˜ˆì œ: ì „ë°©ì— ëŠë¦° ì°¨ëŸ‰ì´ ìˆëŠ” ê²½ìš°
        slow_vehicle_ahead = False
        for detection in detections:
            # ì°¨ëŸ‰ ì†ë„ ì¶”ì • ë¡œì§ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡)
            if detection[4] > 0.6 and detection[5] == 2:  # ì°¨ëŸ‰ í´ë˜ìŠ¤
                slow_vehicle_ahead = True
                break
        
        return slow_vehicle_ahead

# ì‚¬ìš© ì˜ˆì œ
driving_system = AutonomousDriving()
# decision = driving_system.process_frame(current_frame)
```

**ì‹¤í–‰ ê²°ê³¼:**
```
ğŸ¤– ììœ¨ì£¼í–‰ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
ğŸš— ì°¨ëŸ‰ ì¶”ì ê¸° ì´ˆê¸°í™” ì™„ë£Œ
ğŸ“Š 2ê°œ ì°¨ëŸ‰ íƒì§€ë¨
ğŸ†• ìƒˆ ì°¨ëŸ‰ ì¶”ì  ì‹œì‘: ID 0
ğŸ†• ìƒˆ ì°¨ëŸ‰ ì¶”ì  ì‹œì‘: ID 1
ğŸ›‘ ì „ë°© ì¥ì• ë¬¼ ê°ì§€ - ì œë™
```

---

## ğŸ¯ ì¡°ê±´ë¬¸ í™œìš©

### ë‹¤ì¤‘ ì¡°ê±´ ì²˜ë¦¬

```python
# ê°ì²´ íƒ€ì…ë³„ ìƒ‰ìƒ ì§€ì •
def get_object_color(cls):
    """ê°ì²´ í´ë˜ìŠ¤ì— ë”°ë¥¸ ìƒ‰ìƒ ë°˜í™˜"""
    if cls == 0:      # person
        color = (0, 255, 0)      # ë…¹ìƒ‰
        name = "ì‚¬ëŒ"
    elif cls == 2:    # car
        color = (255, 0, 0)      # ë¹¨ê°„ìƒ‰
        name = "ìë™ì°¨"
    elif cls == 3:    # motorcycle
        color = (0, 0, 255)      # íŒŒë€ìƒ‰
        name = "ì˜¤í† ë°”ì´"
    else:
        color = (128, 128, 128)  # íšŒìƒ‰
        name = "ê¸°íƒ€"
    
    print(f"ê°ì²´ ì¢…ë¥˜: {name}, ìƒ‰ìƒ: {color}")
    return color, name

# í™”ë©´ ì˜ì—­ë³„ ì²˜ë¦¬
def determine_zone(center_x, img_width):
    """í™”ë©´ ìœ„ì¹˜ì— ë”°ë¥¸ êµ¬ì—­ íŒë‹¨"""
    if center_x < img_width // 3:
        zone = "left"
        print("ğŸ“ ì¢Œì¸¡ êµ¬ì—­")
    elif center_x > img_width * 2 // 3:
        zone = "right"
        print("ğŸ“ ìš°ì¸¡ êµ¬ì—­")
    else:
        zone = "center"
        print("ğŸ“ ì¤‘ì•™ êµ¬ì—­")
    
    return zone

# ë³µí•© ì¡°ê±´ ì²˜ë¦¬
def find_important_objects(detections, img_shape):
    """ì¤‘ìš”í•œ ê°ì²´ ì°¾ê¸°"""
    important_objects = []
    
    for detection in detections:
        x1, y1, x2, y2, conf, cls = detection
        
        # ë³µí•© ì¡°ê±´: ë†’ì€ ì‹ ë¢°ë„ + íŠ¹ì • í´ë˜ìŠ¤ + í™”ë©´ í•˜ë‹¨
        if (conf > 0.7 and                    # ì‹ ë¢°ë„ 70% ì´ìƒ
            cls in [0, 2, 3] and              # ì‚¬ëŒ, ìë™ì°¨, ì˜¤í† ë°”ì´
            y2 > img_shape[0] * 0.5):         # í™”ë©´ í•˜ë‹¨ 50% ì˜ì—­
            
            important_objects.append([x1, y1, x2, y2])
            print(f"âš ï¸ ì¤‘ìš” ê°ì²´ ë°œê²¬: í´ë˜ìŠ¤ {cls}, ì‹ ë¢°ë„ {conf:.2f}")
    
    return important_objects

# ì‚¬ìš© ì˜ˆì œ
color, name = get_object_color(2)  # ìë™ì°¨
zone = determine_zone(400, 800)    # ì¤‘ì•™ êµ¬ì—­
important = find_important_objects(detections, (600, 800))
```

**ì‹¤í–‰ ê²°ê³¼:**
```
ê°ì²´ ì¢…ë¥˜: ìë™ì°¨, ìƒ‰ìƒ: (255, 0, 0)
ğŸ“ ì¤‘ì•™ êµ¬ì—­
âš ï¸ ì¤‘ìš” ê°ì²´ ë°œê²¬: í´ë˜ìŠ¤ 2, ì‹ ë¢°ë„ 0.85
âš ï¸ ì¤‘ìš” ê°ì²´ ë°œê²¬: í´ë˜ìŠ¤ 0, ì‹ ë¢°ë„ 0.92
```

---

## ğŸ›¡ï¸ ì˜ˆì™¸ ì²˜ë¦¬

### ì•ˆì „í•œ ë°°ì—´ ì ‘ê·¼

```python
def safe_process_detections(detections):
    """ì•ˆì „í•œ íƒì§€ ê²°ê³¼ ì²˜ë¦¬"""
    # íƒì§€ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
    if len(detections) > 0:
        print(f"âœ… {len(detections)}ê°œ ê°ì²´ ì²˜ë¦¬ ì¤‘...")
        
        for i, detection in enumerate(detections):
            try:
                x1, y1, x2, y2, conf, cls = detection
                
                # ì¢Œí‘œ ìœ íš¨ì„± ê²€ì‚¬
                if x1 < 0 or y1 < 0 or x2 <= x1 or y2 <= y1:
                    print(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ì¢Œí‘œ: {detection}")
                    continue
                
                # ì‹ ë¢°ë„ ê²€ì‚¬
                if conf < 0.3:
                    print(f"âš ï¸ ë‚®ì€ ì‹ ë¢°ë„: {conf:.2f}")
                    continue
                
                # ì •ìƒ ì²˜ë¦¬
                process_valid_detection(detection)
                
            except Exception as e:
                print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue
    else:
        print("â„¹ï¸ íƒì§€ëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤")

def process_valid_detection(detection):
    """ìœ íš¨í•œ íƒì§€ ê²°ê³¼ ì²˜ë¦¬"""
    x1, y1, x2, y2, conf, cls = detection
    cx, cy = calculate_center(x1, y1, x2, y2)
    print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: ì¤‘ì‹¬ì ({cx}, {cy}), ì‹ ë¢°ë„ {conf:.2f}")

# ì‚¬ìš© ì˜ˆì œ
test_detections = [
    [100, 200, 300, 400, 0.9, 2],  # ì •ìƒ
    [-10, 150, 200, 350, 0.8, 0],  # ìŒìˆ˜ ì¢Œí‘œ
    [500, 100, 700, 300, 0.2, 1],  # ë‚®ì€ ì‹ ë¢°ë„
]

safe_process_detections(test_detections)
```

**ì‹¤í–‰ ê²°ê³¼:**
```
âœ… 3ê°œ ê°ì²´ ì²˜ë¦¬ ì¤‘...
âœ… ì²˜ë¦¬ ì™„ë£Œ: ì¤‘ì‹¬ì (200, 300), ì‹ ë¢°ë„ 0.90
âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ì¢Œí‘œ: [-10, 150, 200, 350, 0.8, 0]
âš ï¸ ë‚®ì€ ì‹ ë¢°ë„: 0.20
```

---

## âš¡ ì œì–´ë¬¸ (continue, pass)

### continue - ë‹¤ìŒ ë°˜ë³µìœ¼ë¡œ

```python
def process_video_stream():
    """ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ (continue ì‚¬ìš©)"""
    cap = cv2.VideoCapture(0)
    frame_count = 0
    
    while True:
        ret, frame = cap.read()
        frame_count += 1
        
        if not ret:
            print(f"í”„ë ˆì„ {frame_count}: ì½ê¸° ì‹¤íŒ¨")
            continue  # í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨ì‹œ ë‹¤ìŒ í”„ë ˆì„ìœ¼ë¡œ
        
        # í”„ë ˆì„ì´ ë„ˆë¬´ ì–´ë‘ìš°ë©´ ê±´ë„ˆë›°ê¸°
        if np.mean(frame) < 50:
            print(f"í”„ë ˆì„ {frame_count}: ë„ˆë¬´ ì–´ë‘ì›€")
            continue
        
        # íƒì§€ ìˆ˜í–‰
        results = model(frame)
        if len(results[0].boxes) == 0:
            print(f"í”„ë ˆì„ {frame_count}: íƒì§€ ê²°ê³¼ ì—†ìŒ")
            continue  # íƒì§€ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
        
        # ì •ìƒì ì¸ ì²˜ë¦¬
        print(f"í”„ë ˆì„ {frame_count}: ì •ìƒ ì²˜ë¦¬")
        process_detections(results)
        
        # 'q' í‚¤ë¡œ ì¢…ë£Œ
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()

def filter_detections(detections):
    """íƒì§€ ê²°ê³¼ í•„í„°ë§ (continue ì‚¬ìš©)"""
    valid_detections = []
    
    for i, detection in enumerate(detections):
        x1, y1, x2, y2, confidence, cls = detection
        
        # ì‹ ë¢°ë„ ë‚®ì€ íƒì§€ ê±´ë„ˆë›°ê¸°
        if confidence < 0.5:
            print(f"íƒì§€ {i}: ì‹ ë¢°ë„ ë‚®ìŒ ({confidence:.2f})")
            continue
        
        # ê´€ì‹¬ ì—†ëŠ” í´ë˜ìŠ¤ ê±´ë„ˆë›°ê¸°
        if cls not in [0, 2, 3]:  # person, car, motorcycleë§Œ
            print(f"íƒì§€ {i}: ê´€ì‹¬ ì—†ëŠ” í´ë˜ìŠ¤ ({cls})")
            continue
        
        # í™”ë©´ ë°– ê°ì²´ ê±´ë„ˆë›°ê¸°
        if x1 < 0 or y1 < 0:
            print(f"íƒì§€ {i}: í™”ë©´ ë°– ê°ì²´")
            continue
        
        # ìœ íš¨í•œ íƒì§€ë§Œ ì €ì¥
        valid_detections.append(detection)
        print(f"íƒì§€ {i}: ìœ íš¨í•¨ âœ…")
    
    return valid_detections
```

### pass - ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•ŠìŒ

```python
# ë¯¸êµ¬í˜„ í•¨ìˆ˜ í”Œë ˆì´ìŠ¤í™€ë”
def emergency_brake():
    """ê¸´ê¸‰ ì œë™ ì‹œìŠ¤í…œ"""
    # TODO: ê¸´ê¸‰ ì œë™ ë¡œì§ êµ¬í˜„ ì˜ˆì •
    pass

def lane_change_left():
    """ì¢Œì¸¡ ì°¨ì„  ë³€ê²½"""
    # TODO: ì¢Œì¸¡ ì°¨ì„  ë³€ê²½ ë¡œì§ êµ¬í˜„ ì˜ˆì •
    pass

def calculate_safe_distance():
    """ì•ˆì „ê±°ë¦¬ ê³„ì‚°"""
    # TODO: ì•ˆì „ê±°ë¦¬ ê³„ì‚° ë¡œì§ êµ¬í˜„ ì˜ˆì •
    pass

# ì¡°ê±´ë¶€ ì²˜ë¦¬ì—ì„œ ë¹ˆ ë¸”ë¡
def handle_detection_by_class(detection):
    """í´ë˜ìŠ¤ë³„ íƒì§€ ì²˜ë¦¬"""
    cls = detection[5]
    
    if cls == 0:      # person
        handle_pedestrian(detection)
        print("ğŸš¶ ë³´í–‰ì ì²˜ë¦¬")
    elif cls == 2:    # car
        handle_vehicle(detection)
        print("ğŸš— ì°¨ëŸ‰ ì²˜ë¦¬")
    elif cls == 3:    # motorcycle
        handle_motorcycle(detection)
        print("ğŸï¸ ì˜¤í† ë°”ì´ ì²˜ë¦¬")
    else:
        pass  # ë‹¤ë¥¸ ê°ì²´ëŠ” ë¬´ì‹œ
        print("â“ ì•Œ ìˆ˜ ì—†ëŠ” ê°ì²´ - ë¬´ì‹œ")

# ìƒì†ì—ì„œ ë¹ˆ ë©”ì„œë“œ êµ¬í˜„
class BaseSensor:
    """ì„¼ì„œ ê¸°ë³¸ í´ë˜ìŠ¤"""
    def read_data(self):
        raise NotImplementedError("í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„ í•„ìš”")
    
    def calibrate(self):
        raise NotImplementedError("í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„ í•„ìš”")

class LidarSensor(BaseSensor):
    """ë¼ì´ë‹¤ ì„¼ì„œ í´ë˜ìŠ¤"""
    def read_data(self):
        # ë¼ì´ë‹¤ ë°ì´í„° ì½ê¸°
        return self.get_lidar_data()
    
    def calibrate(self):
        pass  # ë¼ì´ë‹¤ëŠ” ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ë˜ë¯€ë¡œ ë³„ë„ ì‘ì—… ë¶ˆí•„ìš”

class CameraSensor(BaseSensor):
    """ì¹´ë©”ë¼ ì„¼ì„œ í´ë˜ìŠ¤"""
    def read_data(self):
        # ì¹´ë©”ë¼ ë°ì´í„° ì½ê¸°
        return self.capture_frame()
    
    def calibrate(self):
        # ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìˆ˜í–‰
        print("ğŸ“· ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìˆ˜í–‰")
        self.perform_calibration()

# ì‚¬ìš© ì˜ˆì œ
lidar = LidarSensor()
camera = CameraSensor()

# ì„¼ì„œ ë°ì´í„° ì½ê¸°
lidar_data = lidar.read_data()
camera_frame = camera.read_data()

# ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìˆ˜í–‰
lidar.calibrate()    # ì•„ë¬´ ì‘ì—… ì•ˆ í•¨ (pass)
camera.calibrate()   # ì‹¤ì œ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìˆ˜í–‰
```

**ì‹¤í–‰ ê²°ê³¼:**
```
í”„ë ˆì„ 1: ì½ê¸° ì‹¤íŒ¨
í”„ë ˆì„ 2: ë„ˆë¬´ ì–´ë‘ì›€
í”„ë ˆì„ 3: íƒì§€ ê²°ê³¼ ì—†ìŒ
í”„ë ˆì„ 4: ì •ìƒ ì²˜ë¦¬
íƒì§€ 0: ì‹ ë¢°ë„ ë‚®ìŒ (0.35)
íƒì§€ 1: ìœ íš¨í•¨ âœ…
íƒì§€ 2: ê´€ì‹¬ ì—†ëŠ” í´ë˜ìŠ¤ (7)
ğŸš¶ ë³´í–‰ì ì²˜ë¦¬
ğŸš— ì°¨ëŸ‰ ì²˜ë¦¬
â“ ì•Œ ìˆ˜ ì—†ëŠ” ê°ì²´ - ë¬´ì‹œ
ğŸ“· ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìˆ˜í–‰
```

---

## ğŸ¯ ì‹¤ì „ í†µí•© ì˜ˆì œ

### ì™„ì „í•œ ììœ¨ì£¼í–‰ ì‹œìŠ¤í…œ

```python
import cv2
import numpy as np
from datetime import datetime

class CompleteAutonomousSystem:
    """ì™„ì „í•œ ììœ¨ì£¼í–‰ ì‹œìŠ¤í…œ ì˜ˆì œ"""
    
    def __init__(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.vehicle_tracker = VehicleTracker()
        self.detection_history = []
        self.frame_count = 0
        self.start_time = datetime.now()
        
        print("ğŸš€ í†µí•© ììœ¨ì£¼í–‰ ì‹œìŠ¤í…œ ì‹œì‘")
        print(f"ì‹œì‘ ì‹œê°„: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    def run_system(self, video_source=0):
        """ì‹œìŠ¤í…œ ì‹¤í–‰"""
        cap = cv2.VideoCapture(video_source)
        
        if not cap.isOpened():
            print("âŒ ë¹„ë””ì˜¤ ì†ŒìŠ¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
        
        print("ğŸ“¹ ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì‹œì‘")
        
        while True:
            # í”„ë ˆì„ ì½ê¸°
            ret, frame = cap.read()
            self.frame_count += 1
            
            if not ret:
                print(f"í”„ë ˆì„ {self.frame_count}: ì½ê¸° ì‹¤íŒ¨")
                continue
            
            # í”„ë ˆì„ ì „ì²˜ë¦¬ ë° ê²€ì¦
            if not self.validate_frame(frame):
                continue
            
            # ê°ì²´ íƒì§€ ìˆ˜í–‰
            detections = self.detect_objects(frame)
            
            if len(detections) == 0:
                continue
            
            # íƒì§€ ê²°ê³¼ í•„í„°ë§
            valid_detections = self.filter_detections(detections)
            
            # ì°¨ëŸ‰ ì¶”ì  ì—…ë°ì´íŠ¸
            self.vehicle_tracker.update_tracks(valid_detections)
            
            # ì£¼í–‰ ê²°ì •
            decision = self.make_decision(valid_detections, frame.shape)
            
            # ê²°ê³¼ í‘œì‹œ
            annotated_frame = self.draw_annotations(frame, valid_detections)
            
            # í†µê³„ í‘œì‹œ
            self.display_stats(annotated_frame)
            
            # í™”ë©´ ì¶œë ¥
            cv2.imshow('ììœ¨ì£¼í–‰ ì‹œìŠ¤í…œ', annotated_frame)
            
            # 'q' í‚¤ë¡œ ì¢…ë£Œ
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        # ì •ë¦¬
        cap.release()
        cv2.destroyAllWindows()
        self.print_final_stats()
    
    def validate_frame(self, frame):
        """í”„ë ˆì„ ìœ íš¨ì„± ê²€ì‚¬"""
        # í”„ë ˆì„ì´ ë„ˆë¬´ ì–´ë‘ìš´ì§€ í™•ì¸
        if np.mean(frame) < 30:
            return False
        
        # í”„ë ˆì„ í¬ê¸° í™•ì¸
        if frame.shape[0] < 100 or frame.shape[1] < 100:
            return False
        
        return True
    
    def detect_objects(self, frame):
        """ê°ì²´ íƒì§€ (ì‹œë®¬ë ˆì´ì…˜)"""
        # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” YOLO ë“±ì˜ ëª¨ë¸ ì‚¬ìš©
        # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±
        detections = []
        
        # ë¬´ì‘ìœ„ë¡œ ëª‡ ê°œì˜ ê°ì²´ ìƒì„± (ë°ëª¨ìš©)
        num_objects = np.random.randint(0, 4)
        
        for _ in range(num_objects):
            x1 = np.random.randint(0, frame.shape[1] - 100)
            y1 = np.random.randint(0, frame.shape[0] - 100)
            x2 = x1 + np.random.randint(50, 150)
            y2 = y1 + np.random.randint(50, 150)
            conf = np.random.uniform(0.3, 0.95)
            cls = np.random.choice([0, 2, 3, 7])  # person, car, motorcycle, truck
            
            detections.append([x1, y1, x2, y2, conf, cls])
        
        return detections
    
    def filter_detections(self, detections):
        """íƒì§€ ê²°ê³¼ í•„í„°ë§"""
        valid_detections = []
        
        for i, detection in enumerate(detections):
            x1, y1, x2, y2, conf, cls = detection
            
            # ì‹ ë¢°ë„ í•„í„°
            if conf < 0.5:
                continue
            
            # í´ë˜ìŠ¤ í•„í„° (ê´€ì‹¬ ìˆëŠ” ê°ì²´ë§Œ)
            if cls not in [0, 2, 3]:  # person, car, motorcycle
                continue
            
            # ì¢Œí‘œ ìœ íš¨ì„± ê²€ì‚¬
            if x1 < 0 or y1 < 0 or x2 <= x1 or y2 <= y1:
                continue
            
            valid_detections.append(detection)
        
        return valid_detections
    
    def make_decision(self, detections, frame_shape):
        """ì£¼í–‰ ê²°ì •"""
        decision = {
            'action': 'continue',
            'reason': 'ì •ìƒ ì£¼í–‰',
            'risk_level': 'low'
        }
        
        for detection in detections:
            x1, y1, x2, y2, conf, cls = detection
            cx, cy = calculate_center(x1, y1, x2, y2)
            
            # ìœ„í—˜ êµ¬ì—­ í™•ì¸
            if is_in_danger_zone(cx, cy, frame_shape[1], frame_shape[0]):
                if cls == 0:  # ì‚¬ëŒ
                    decision = {
                        'action': 'emergency_brake',
                        'reason': 'ë³´í–‰ì ê°ì§€',
                        'risk_level': 'high'
                    }
                    break
                elif cls in [2, 3]:  # ì°¨ëŸ‰, ì˜¤í† ë°”ì´
                    decision = {
                        'action': 'brake',
                        'reason': 'ì „ë°© ì°¨ëŸ‰',
                        'risk_level': 'medium'
                    }
        
        return decision
    
    def draw_annotations(self, frame, detections):
        """ê²€ì¶œ ê²°ê³¼ ì‹œê°í™”"""
        annotated = frame.copy()
        
        for detection in detections:
            x1, y1, x2, y2, conf, cls = detection
            
            # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ
            color, name = get_object_color(cls)
            
            # ë°”ìš´ë”© ë°•ìŠ¤
            cv2.rectangle(annotated, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
            
            # ë¼ë²¨
            label = f"{name} {conf:.2f}"
            cv2.putText(annotated, label, (int(x1), int(y1)-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
            
            # ì¤‘ì‹¬ì 
            cx, cy = calculate_center(x1, y1, x2, y2)
            cv2.circle(annotated, (cx, cy), 5, color, -1)
        
        return annotated
    
    def display_stats(self, frame):
        """í†µê³„ ì •ë³´ í‘œì‹œ"""
        current_time = datetime.now()
        elapsed = (current_time - self.start_time).total_seconds()
        fps = self.frame_count / elapsed if elapsed > 0 else 0
        
        # í†µê³„ í…ìŠ¤íŠ¸
        stats_text = [
            f"í”„ë ˆì„: {self.frame_count}",
            f"FPS: {fps:.1f}",
            f"ì¶”ì  ì¤‘: {len(self.vehicle_tracker.tracks)}",
            f"ì´ íƒì§€: {len(self.detection_history)}"
        ]
        
        # í™”ë©´ì— í‘œì‹œ
        for i, text in enumerate(stats_text):
            cv2.putText(frame, text, (10, 30 + i*25), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    
    def print_final_stats(self):
        """ìµœì¢… í†µê³„ ì¶œë ¥"""
        end_time = datetime.now()
        total_time = (end_time - self.start_time).total_seconds()
        avg_fps = self.frame_count / total_time if total_time > 0 else 0
        
        print("\n" + "="*50)
        print("ğŸ“Š ìµœì¢… ì‹¤í–‰ í†µê³„")
        print("="*50)
        print(f"ì´ ì‹¤í–‰ ì‹œê°„: {total_time:.1f}ì´ˆ")
        print(f"ì²˜ë¦¬í•œ í”„ë ˆì„: {self.frame_count}ê°œ")
        print(f"í‰ê·  FPS: {avg_fps:.1f}")
        print(f"ì´ íƒì§€ ìˆ˜: {len(self.detection_history)}ê°œ")
        print(f"ìµœëŒ€ ë™ì‹œ ì¶”ì : {max(len(self.vehicle_tracker.tracks), 1)}ê°œ")
        print("="*50)

# ì‹œìŠ¤í…œ ì‹¤í–‰
if __name__ == "__main__":
    system = CompleteAutonomousSystem()
    
    try:
        system.run_system()  # ì›¹ìº  ì‚¬ìš©
        # system.run_system('video.mp4')  # ë¹„ë””ì˜¤ íŒŒì¼ ì‚¬ìš©
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
```

---

## ğŸ“š ì¶”ê°€ í•™ìŠµ ìë£Œ

### ìœ ìš©í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤

```python
# ì»´í“¨í„° ë¹„ì „
import cv2          # OpenCV - ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ì²˜ë¦¬
import numpy as np  # NumPy - ìˆ˜ì¹˜ ì—°ì‚°

# ë”¥ëŸ¬ë‹/AI
import torch        # PyTorch
import ultralytics  # YOLO
import tensorflow   # TensorFlow

# ë°ì´í„° ì²˜ë¦¬
import pandas as pd # ë°ì´í„° ë¶„ì„
import matplotlib.pyplot as plt  # ì‹œê°í™”

# ì‹œê°„/ë‚ ì§œ
from datetime import datetime
import time
```

### ì„±ëŠ¥ ìµœì í™” íŒ

```python
# 1. ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ ì‚¬ìš©
# ëŠë¦° ë°©ë²•
filtered_detections = []
for detection in detections:
    if detection[4] > 0.5:  # ì‹ ë¢°ë„
        filtered_detections.append(detection)

# ë¹ ë¥¸ ë°©ë²•
filtered_detections = [d for d in detections if d[4] > 0.5]

# 2. NumPy ë²¡í„°í™” ì—°ì‚°
# ëŠë¦° ë°©ë²• (ë°˜ë³µë¬¸)
centers = []
for detection in detections:
    x1, y1, x2, y2 = detection[:4]
    cx = (x1 + x2) / 2
    cy = (y1 + y2) / 2
    centers.append((cx, cy))

# ë¹ ë¥¸ ë°©ë²• (ë²¡í„°í™”)
boxes = np.array([d[:4] for d in detections])
centers = (boxes[:, [0, 1]] + boxes[:, [2, 3]]) / 2

# 3. ì¡°ê¸° ì¢…ë£Œ í™œìš©
def find_high_confidence_detection(detections, threshold=0.9):
    for detection in detections:
        if detection[4] > threshold:
            return detection  # ì°¾ìœ¼ë©´ ì¦‰ì‹œ ë°˜í™˜
    return None  # ì—†ìœ¼ë©´ None ë°˜í™˜
```

---

## ğŸ”§ ë””ë²„ê¹… íŒ

```python
# 1. ë¡œê¹… ì¶”ê°€
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def process_detection_with_logging(detection):
    logger.info(f"íƒì§€ ì²˜ë¦¬ ì‹œì‘: {detection}")
    
    try:
        # ì²˜ë¦¬ ë¡œì§
        result = process_detection(detection)
        logger.info(f"ì²˜ë¦¬ ì™„ë£Œ: {result}")
        return result
    except Exception as e:
        logger.error(f"ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return None

# 2. ì–´ì„¤ì…˜ ì‚¬ìš©
def validate_detection(detection):
    assert len(detection) == 6, f"íƒì§€ ë°ì´í„° ê¸¸ì´ ì˜¤ë¥˜: {len(detection)}"
    assert detection[4] >= 0 and detection[4] <= 1, f"ì‹ ë¢°ë„ ë²”ìœ„ ì˜¤ë¥˜: {detection[4]}"
    assert detection[2] > detection[0], f"x2ê°€ x1ë³´ë‹¤ ì‘ìŒ: {detection}"
    assert detection[3] > detection[1], f"y2ê°€ y1ë³´ë‹¤ ì‘ìŒ: {detection}"

# 3. ì‹œê°ì  ë””ë²„ê¹…
def debug_draw_detections(frame, detections):
    """ë””ë²„ê¹…ìš© ì‹œê°í™”"""
    debug_frame = frame.copy()
    
    for i, detection in enumerate(detections):
        x1, y1, x2, y2, conf, cls = detection
        
        # ê° íƒì§€ì— ë²ˆí˜¸ í‘œì‹œ
        cv2.putText(debug_frame, str(i), (int(x1), int(y1)), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)
        
        # ìì„¸í•œ ì •ë³´ í‘œì‹œ
        info = f"ID:{i} C:{conf:.2f} Cls:{cls}"
        cv2.putText(debug_frame, info, (int(x1), int(y2)+20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)
    
    return debug_frame
```

---

## ğŸ“ ë§ˆë¬´ë¦¬

ì´ ê°€ì´ë“œì—ì„œ ë‹¤ë£¬ Python í•µì‹¬ ë¬¸ë²•ë“¤ì€ ììœ¨ì£¼í–‰ ì‹œìŠ¤í…œ ê°œë°œì˜ ê¸°ì´ˆê°€ ë©ë‹ˆë‹¤. ê° ë¬¸ë²• ìš”ì†Œë“¤ì´ ì‹¤ì œ ì–´ë–»ê²Œ í™œìš©ë˜ëŠ”ì§€ ì´í•´í•˜ê³ , ì‹¤ì „ í”„ë¡œì íŠ¸ì—ì„œ ì‘ìš©í•´ë³´ì„¸ìš”.

### ë‹¤ìŒ ë‹¨ê³„ í•™ìŠµ ê¶Œì¥ì‚¬í•­

1. **OpenCV ì‹¬í™”**: ì´ë¯¸ì§€ ì²˜ë¦¬ ê³ ê¸‰ ê¸°ë²•
2. **YOLO ëª¨ë¸**: ì‹¤ì‹œê°„ ê°ì²´ íƒì§€
3. **ì¹¼ë§Œ í•„í„°**: ê°ì²´ ì¶”ì  ì•Œê³ ë¦¬ì¦˜
4. **ROS (Robot Operating System)**: ë¡œë´‡ ì†Œí”„íŠ¸ì›¨ì–´ í”Œë«í¼
5. **ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬**: PyTorch, TensorFlow

### ì¶”ê°€ ë¦¬ì†ŒìŠ¤

- [OpenCV ê³µì‹ ë¬¸ì„œ](https://docs.opencv.org/)
- [Ultralytics YOLO](https://github.com/ultralytics/ultralytics)
- [ììœ¨ì£¼í–‰ ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸](https://github.com/topics/autonomous-driving)

---

**ğŸ’¡ íŒ**: ì´ ê°€ì´ë“œì˜ ëª¨ë“  ì½”ë“œëŠ” ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ê° ì˜ˆì œë¥¼ ì§ì ‘ ì‹¤í–‰í•´ë³´ë©° í•™ìŠµí•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤!

**ğŸ“ ê¸°ì—¬**: ì´ ê°€ì´ë“œì— ê°œì„ ì‚¬í•­ì´ë‚˜ ì¶”ê°€í•  ë‚´ìš©ì´ ìˆë‹¤ë©´ ì–¸ì œë“  PRì„ ë³´ë‚´ì£¼ì„¸ìš”!
